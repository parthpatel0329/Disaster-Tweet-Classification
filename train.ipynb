{"cells":[{"cell_type":"code","execution_count":1,"id":"318e8783","metadata":{"id":"318e8783","executionInfo":{"status":"ok","timestamp":1681935405648,"user_tz":240,"elapsed":9616,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import gensim.downloader as api\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":2,"id":"bb0becc5","metadata":{"id":"bb0becc5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681935452006,"user_tz":240,"elapsed":46366,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}},"outputId":"ae96366a-99c7-4f01-de2e-f2e9af6343a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 66.0/66.0MB downloaded\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["words = api.load(\"glove-wiki-gigaword-50\")\n","nltk.download('wordnet')"]},{"cell_type":"code","source":["# import os\n","# os.chdir('/content/drive/MyDrive/NLP/Natural-Language-Processing-with-Disaster-Tweets-master/Codes')"],"metadata":{"id":"Ne7D9sHqKuDg","executionInfo":{"status":"ok","timestamp":1681935519008,"user_tz":240,"elapsed":7,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"id":"Ne7D9sHqKuDg","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":15,"id":"da5b813a","metadata":{"id":"da5b813a","executionInfo":{"status":"ok","timestamp":1681935683231,"user_tz":240,"elapsed":2,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["data = pd.read_csv('data.csv')"]},{"cell_type":"code","execution_count":7,"id":"d203e559","metadata":{"id":"d203e559","executionInfo":{"status":"ok","timestamp":1681935533588,"user_tz":240,"elapsed":2376,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n","lemmatizer = WordNetLemmatizer()\n","\n","def make_tokens(s):\n","    s = s.lower()\n","    tokens = tokenizer.tokenize(s)\n","    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n","    return [t for t in tokens if t in words]\n","\n","def wordVectors(s):\n","    lis = make_tokens(s)\n","    v = []\n","\n","    for token in lis:\n","        \n","        if token not in words:\n","            continue\n","    \n","        if token not in t:\n","            t[token] = ind[0]\n","            w.append(words[token])\n","            ind[0] += 1\n","        \n","        v.append(np.array(t[token]).reshape(1))\n","        \n","    return np.array(v, dtype=float)\n","\n","def padding(df, colName):\n","    sequences = []\n","    \n","    for i in range(df.shape[0]):\n","        seq = wordVectors(df[colName][i])\n","        \n","        if seq.shape[0] == 0:\n","            seq = np.zeros(shape=(1, 1))\n","        \n","        sequences.append(seq)\n","    \n","    cpy = [arr.copy() for arr in sequences]\n","    \n","    for i in range(len(sequences)):\n","        cpy[i] = np.concatenate([sequences[i], np.zeros(shape=(35-sequences[i].shape[0], 1))])\n","        \n","    return np.array(cpy).astype(int)\n","\n","def makeDf(df,colName):\n","    return padding(df, colName)\n","\n","t = {}\n","w = [np.zeros(50).astype(float)]\n","ind = [1]\n","\n","X = makeDf(data.copy(),'tweet')\n","y = data['label'].to_numpy()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","w = np.stack(w, axis=0)\n","w = torch.from_numpy(w).float()"]},{"cell_type":"code","execution_count":8,"id":"378692a2","metadata":{"id":"378692a2","executionInfo":{"status":"ok","timestamp":1681935538262,"user_tz":240,"elapsed":3,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["class RNN(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, emb):\n","        super(RNN, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_size, num_classes)\n","        self.embed = torch.nn.Embedding.from_pretrained(emb)\n","        \n","    def forward(self, x):\n","        x = self.embed(x)[:,0,:,:]\n","        x = torch.transpose(x, 2, 1)\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        out, _ = self.rnn(x, h0)\n","        out = out.mean(dim=1)\n","        out = self.fc(out)\n","        out = torch.squeeze(out,1)\n","        return out"]},{"cell_type":"code","execution_count":9,"id":"8bbe128b","metadata":{"id":"8bbe128b","executionInfo":{"status":"ok","timestamp":1681935544309,"user_tz":240,"elapsed":473,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["class LSTM(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, emb, bidirectional=False):\n","        super(LSTM, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.bidirectional = bidirectional\n","        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=self.bidirectional)\n","        \n","        self.fc = None\n","        if self.bidirectional:\n","            self.fc = torch.nn.Linear(hidden_size*2, num_classes)\n","        else:\n","            self.fc = torch.nn.Linear(hidden_size, num_classes)\n","        \n","        self.embed = torch.nn.Embedding.from_pretrained(emb)\n","        \n","    def forward(self, x):\n","        x = self.embed(x)[:,0,:,:]\n","        x = torch.transpose(x, 2, 1)\n","        h0 = None\n","        c0 = None\n","        \n","        if self.bidirectional:\n","            h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","            c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","        else:\n","            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        \n","        out, _ = self.lstm(x, (h0,c0))\n","        out = out.mean(dim=1)\n","        out = self.fc(out)\n","        out = torch.squeeze(out,1)\n","        return out"]},{"cell_type":"code","execution_count":10,"id":"8aed7d10","metadata":{"id":"8aed7d10","executionInfo":{"status":"ok","timestamp":1681935549066,"user_tz":240,"elapsed":1282,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["class DAN(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes, emb):\n","        super(DAN, self).__init__()\n","        self.layers = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size),\n","                                          torch.nn.ReLU(),\n","                                          torch.nn.Linear(hidden_size, num_classes))\n","        self.embed = torch.nn.Embedding.from_pretrained(emb)\n","    def forward(self, x):\n","        x = self.embed(x)[:,0,:,:]\n","        x = torch.transpose(x, 2, 1)\n","        x = x.mean(dim=1)\n","        x = self.layers(x)\n","        x = torch.squeeze(x,1)\n","        return x"]},{"cell_type":"code","execution_count":11,"id":"2f3f65a1","metadata":{"id":"2f3f65a1","executionInfo":{"status":"ok","timestamp":1681935551526,"user_tz":240,"elapsed":1,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["#fixed\n","num_classes = 1\n","num_layers = 1\n","batch_size = 30\n","input_size = 35\n","sequence_length = 1"]},{"cell_type":"code","execution_count":12,"id":"7806568b","metadata":{"id":"7806568b","executionInfo":{"status":"ok","timestamp":1681935557255,"user_tz":240,"elapsed":3,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["train_dataset = []\n","for i in range(len(X_train)):\n","    train_dataset.append([torch.from_numpy(X_train[i]), y_train[i]])\n","    \n","test_dataset = []\n","for i in range(len(X_test)):\n","    test_dataset.append(torch.from_numpy(X_test[i]))\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":13,"id":"6d94ab4d","metadata":{"id":"6d94ab4d","executionInfo":{"status":"ok","timestamp":1681935558809,"user_tz":240,"elapsed":8,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":["dan_params = {'num_epochs':150, 'learning_rate':0.1, 'hidden_size':50}\n","rnn_params = {'num_epochs':25, 'learning_rate':0.1, 'hidden_size':50}\n","lstm_params = {'num_epochs':100, 'learning_rate':0.1, 'hidden_size':50}\n","bilstm_params = {'num_epochs':20, 'learning_rate':1, 'hidden_size':50}"]},{"cell_type":"code","execution_count":14,"id":"7644a2ce","metadata":{"id":"7644a2ce","executionInfo":{"status":"ok","timestamp":1681935681617,"user_tz":240,"elapsed":119272,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b5085e1-d19d-4166-b621-d916ca216514"},"outputs":[{"output_type":"stream","name":"stdout","text":["RNN\n","Train Accuracy: 0.7326765188834155\n","Test Accuracy: 0.7367038739330269\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.85      0.79       874\n","           1       0.74      0.59      0.66       649\n","\n","    accuracy                           0.74      1523\n","   macro avg       0.74      0.72      0.72      1523\n","weighted avg       0.74      0.74      0.73      1523\n","\n","LSTM\n","Train Accuracy: 0.819047619047619\n","Test Accuracy: 0.7150361129349967\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.74      0.75       874\n","           1       0.66      0.67      0.67       649\n","\n","    accuracy                           0.72      1523\n","   macro avg       0.71      0.71      0.71      1523\n","weighted avg       0.72      0.72      0.72      1523\n","\n","Bi-LSTM\n","Train Accuracy: 0.7479474548440066\n","Test Accuracy: 0.7150361129349967\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.80      0.76       874\n","           1       0.69      0.60      0.64       649\n","\n","    accuracy                           0.72      1523\n","   macro avg       0.71      0.70      0.70      1523\n","weighted avg       0.71      0.72      0.71      1523\n","\n","DAN\n","Train Accuracy: 0.6218390804597701\n","Test Accuracy: 0.6014445173998687\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.77      0.69       874\n","           1       0.55      0.37      0.44       649\n","\n","    accuracy                           0.60      1523\n","   macro avg       0.59      0.57      0.57      1523\n","weighted avg       0.59      0.60      0.58      1523\n","\n"]}],"source":["for mod in ['RNN','LSTM','Bi-LSTM','DAN']:\n","    print(mod)\n","    model = None\n","    if mod == 'RNN':\n","        num_epochs = rnn_params['num_epochs']\n","        learning_rate = rnn_params['learning_rate']\n","        hidden_size = rnn_params['hidden_size']\n","        model = RNN(input_size, hidden_size, num_layers, num_classes, w).to(device)\n","    if mod == 'LSTM':\n","        num_epochs = lstm_params['num_epochs']\n","        learning_rate = lstm_params['learning_rate']\n","        hidden_size = lstm_params['hidden_size']\n","        model = LSTM(input_size, hidden_size, num_layers, num_classes, w, bidirectional=False).to(device)\n","    if mod == 'Bi-LSTM':\n","        num_epochs = bilstm_params['num_epochs']\n","        learning_rate = bilstm_params['learning_rate']\n","        hidden_size = bilstm_params['hidden_size']\n","        model = LSTM(input_size, hidden_size, num_layers, num_classes, w, bidirectional=True).to(device)\n","    if mod == 'DAN':\n","        num_epochs = dan_params['num_epochs']\n","        learning_rate = dan_params['learning_rate']\n","        hidden_size = dan_params['hidden_size']\n","        model = DAN(input_size, hidden_size, num_classes, w).to(device)\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","    loss_values = []\n","    n_total_steps = len(train_loader)\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for i, (inp,labels) in enumerate(train_loader):\n","            inp = inp.reshape(-1, sequence_length, input_size).to(device)\n","            labels = labels.to(device)\n","          \n","            outputs = model(inp)\n","            loss = criterion(outputs, labels.float())\n","          \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","          \n","          #if (i+1) % 50 == 0:\n","          #    print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","          \n","            running_loss += loss.item() * inp.size(0)\n","          \n","        loss_values.append(running_loss / len(train_dataset))\n","\n","    y_pred = []\n","    y_true = y_train.tolist()\n","\n","    with torch.no_grad():\n","        for (inp,labels) in train_loader:\n","            inp = inp.reshape(-1, sequence_length, input_size).to(device)\n","              \n","            outputs = model(inp)\n","            predicted = torch.where(outputs >= 0.0, 1, 0)\n","            y_pred.extend(predicted.tolist())\n","\n","    print('Train Accuracy:', accuracy_score(y_train, y_pred))\n","\n","    y_pred = []\n","    y_true = y_test.tolist()\n","\n","    with torch.no_grad():\n","        for (inp) in test_loader:\n","            inp = inp.reshape(-1, sequence_length, input_size).to(device)\n","              \n","            outputs = model(inp)\n","            predicted = torch.where(outputs >= 0.0, 1, 0)\n","            y_pred.extend(predicted.tolist())\n","\n","    print('Test Accuracy:', accuracy_score(y_test, y_pred))\n","    print('Classification Report:')\n","    print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":16,"id":"931d9184","metadata":{"id":"931d9184","executionInfo":{"status":"ok","timestamp":1681935687468,"user_tz":240,"elapsed":27,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c551840-da6e-4ea8-e7bf-32f474526513"},"outputs":[{"output_type":"stream","name":"stdout","text":["SVM:\n","Train Accuracy: 0.9775041050903119\n","Test Accuracy: 0.7977675640183848\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.87      0.83       874\n","           1       0.80      0.70      0.75       649\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.80      0.79      0.79      1523\n","weighted avg       0.80      0.80      0.80      1523\n","\n"]}],"source":["#SVM\n","print('SVM:')\n","tfidf = TfidfVectorizer()\n","classifier = LinearSVC(tol=0.01,random_state = 42)\n","X = data['tweet']\n","y = data['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","tfidf.fit(X)\n","X_train = tfidf.transform(X_train)\n","X_test = tfidf.transform(X_test)\n","classifier.fit(X_train,y_train )\n","y_pred = classifier.predict(X_train)\n","print('Train Accuracy:', accuracy_score(y_train, y_pred))\n","y_pred = classifier.predict(X_test)\n","print('Test Accuracy:', accuracy_score(y_test, y_pred))\n","print('Classification Report:')\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"id":"60f64de3","metadata":{"id":"60f64de3","executionInfo":{"status":"aborted","timestamp":1681935452971,"user_tz":240,"elapsed":36,"user":{"displayName":"Sowmya J Iyer","userId":"04501433217452218309"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}